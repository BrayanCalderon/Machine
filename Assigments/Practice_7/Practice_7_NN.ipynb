{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJLmvD0bFE78"
   },
   "source": [
    "# Practice problems 7\n",
    "# [Machine Learning](https://dis.unal.edu.co/~fgonza/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm1vQFIkFE8A"
   },
   "source": [
    "The following code implements a feed-forward neural network with one hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nrvlVuyFFE8A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def predict(w, x):\n",
    "    a = np.zeros((3,))\n",
    "    a[2] = relu(np.dot(x,w[6:8]) + w[8])\n",
    "    a[1] = relu(np.dot(x,w[3:5]) + w[5])\n",
    "    a[0] = sigmoid(np.dot(a[1:3], w[0:2]) + w[2])\n",
    "    return a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJ2-dQdbFE8C"
   },
   "source": [
    "### 1.\n",
    "Find a weight vector such that the neural network calculates the negated XOR function:\n",
    "    \n",
    "$$f(x,y)=\\neg(x\\text{ xor }y)$$\n",
    "\n",
    "Use the following function to test your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "ufaaQPqoFE8C",
    "outputId": "65747ebd-a682-485b-8f15-3db9f7be0051"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (0,) not aligned: 2 (dim 0) != 0 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31852/1592080639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m  [1, 1]]\n\u001b[1;32m     15\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtest_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_31852/1592080639.py\u001b[0m in \u001b[0;36mtest_prediction\u001b[0;34m(X, Y, w)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31852/4047360200.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(w, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,) and (0,) not aligned: 2 (dim 0) != 0 (dim 0)"
     ]
    }
   ],
   "source": [
    "def test_prediction(X, Y, w):\n",
    "    epsilon = 0.001\n",
    "    for i, x in enumerate(X):\n",
    "        print (x, predict(w, x))\n",
    "        if np.abs(predict(w, x) - Y[i]) > epsilon: \n",
    "            raise Exception(\"Prediction error\")\n",
    "    return True\n",
    "\n",
    "w = np.zeros(9) # you have to modify this vector\n",
    "\n",
    "X = [[0, 0],\n",
    " [0, 1],\n",
    " [1, 0],\n",
    " [1, 1]]\n",
    "Y = [1, 0, 0 ,1]\n",
    "test_prediction(X, Y, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M61f9mjOFE8D"
   },
   "source": [
    "### 2.\n",
    "\n",
    "Suppose that we have a cross entropy loss function:\n",
    "\n",
    "$$L(w, x, y) = - y \\log f_w(x) - (1-y) \\log (1-f_w(x))$$\n",
    "\n",
    "where $f_w(x)$ corresponds to the prediction of the neural network from the  previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlwtEDSoFE8E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(w, x, y):\n",
    "    return -y * np.log(predict(w, x)) -(1. - y) * np.log(1. - predict(w, x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7AIo_-7FE8E"
   },
   "source": [
    "Write a function that calculates the gradient of the loss with respect to the weights:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4pyiyyVFE8E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dL_dw(w, x, y):\n",
    "    delta = np.zeros(len(w))\n",
    "    # put your code here\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JDfuwzVFE8F"
   },
   "source": [
    "Use the following functions to test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "29TFtU9KMiyb",
    "outputId": "f626dcd8-247a-4921-fc2f-a852bd8ba41c"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dfa140f93a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtest_dL_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-dfa140f93a06>\u001b[0m in \u001b[0;36mtest_dL_dw\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdL_dw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dL_dw test failed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: dL_dw test failed!"
     ]
    }
   ],
   "source": [
    "tws = np.array([[-0.70032787,  0.05195189,  0.02322052,  1.4555916 ,  0.12168937,\n",
    "        -0.93580307, -0.58649814, -0.25847014, -0.11531032],\n",
    "       [ 1.11732048,  0.60225913,  0.05929297, -1.09018787,  2.33186956,\n",
    "         0.68248461, -0.16774443, -0.12996126,  0.31700533],\n",
    "       [ 0.80285183,  0.08585098,  1.62153749,  0.61251705,  0.18263732,\n",
    "         2.08412764, -0.2940164 , -0.72975557, -1.33828478],\n",
    "       [-0.74973286,  1.24623671,  0.63761743,  2.13714693,  0.90258674,\n",
    "         1.70238408, -2.60308453,  0.03070776,  2.34519973]])\n",
    "txs = np.array([[-0.96460511,  0.79790901],\n",
    "       [ 0.34546505,  0.92062212],\n",
    "       [-0.85750439,  0.50268203],\n",
    "       [ 0.69988938,  2.07328522]])\n",
    "tys = np.array([[ 0.66453404],\n",
    "       [-1.35012527],\n",
    "       [-0.7976646 ],\n",
    "       [ 0.57095802]])\n",
    "tls = np.array([[ 0.        , -0.03798627, -0.1555583 ,  0.        ,  0.        ,\n",
    "         0.        ,  0.0077955 , -0.00644834, -0.00808155],\n",
    "       [ 5.63408329,  0.32024725,  2.29715661,  0.88669136,  2.36292409,\n",
    "         2.56666012,  0.47794521,  1.27366556,  1.38348354],\n",
    "       [ 2.8850554 ,  0.        ,  1.74777687, -1.20325518,  0.70536637,\n",
    "         1.40320586,  0.        ,  0.        ,  0.        ],\n",
    "       [-2.48486794, -0.2877231 , -0.49016324,  0.25720339,  0.76191466,\n",
    "         0.36749148, -0.42753402, -1.26648581, -0.61085942]])\n",
    "\n",
    "def test_dL_dw():\n",
    "    num_tests = tws.shape[0]\n",
    "    epsilon = 0.0001\n",
    "    for i in range(num_tests):\n",
    "        tw = tws[i]\n",
    "        tx = txs[i]\n",
    "        ty = tys[i]\n",
    "        tl = tls[i]\n",
    "        if np.linalg.norm(dL_dw(tw, tx, ty) - tl) > epsilon:\n",
    "            raise Exception(\"dL_dw test failed!\")\n",
    "    return True\n",
    "\n",
    "test_dL_dw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    #(≈ 4 lines of code)\n",
    "    # W1 = ...\n",
    "    # b1 = ...\n",
    "    # W2 = ...\n",
    "    # b2 = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    W1 = np.random.randn(n_h,n_x)*0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.01624345 -0.00611756]\n",
      " [-0.00528172 -0.01072969]]\n",
      "b1 = [[0.]\n",
      " [0.]]\n",
      "W2 = [[ 0.00865408 -0.02301539]\n",
      " [ 0.01744812 -0.00761207]\n",
      " [ 0.00319039 -0.0024937 ]\n",
      " [ 0.01462108 -0.02060141]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(2,2,4)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    #(≈ 1 line of code)\n",
    "    # Z = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    Z = np.dot(W,A)+b\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z,cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_Z,t_linear_cache = linear_forward()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Practice 7 NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
