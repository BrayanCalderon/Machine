{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eae1048",
   "metadata": {},
   "source": [
    "# Practice Problems 1 - Linear Algebra and probability\n",
    "### Brayan José Calderón Amorocho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223f94e",
   "metadata": {},
   "source": [
    "1. Do the tutorial “Kaggle Python Tutorial on Machine Learning” (https://www.datacamp.com/courses/kaggle-python-tutorial-on-machine-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5006c5c",
   "metadata": {},
   "source": [
    "![](certificate.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8193a05",
   "metadata": {},
   "source": [
    "\n",
    "2. Let $D = (d_1, . . . , d_n)$ be a set of documents and $T = (t_1, . . . , t_m)$ a set of terms (words). Let $TD = (TD_{i,j})_{i=1...m,j=1...n}$ be a matrix such that $TD_{i,j}$ corresponds to the number of times the term $t_i$ appears in the document $d_j$ . Also, let $l_i$ be the length, number of characters,of term $t_i$ , and let $L = (l_1, . . . , l_m)$ be a column vector. Finally, assume a process where a document $d_j$ is randomly chosen with uniform probability and then a term $t_i$ , present in $d_j$ , is randomly chosen with a probability proportional to the frequency of $t_i$ in $d_j$ .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172533b6",
   "metadata": {},
   "source": [
    "For all the following expressions you must provide:\n",
    "- a mathematical expression to calculate it that includes $T D, L$, constants (scalars, vectors or matrices) and linear algebra operations\n",
    "- a expression in Numpy (http://www.scipy.org) that, when evaluated, generates the requested matrix, vector or scalar (the expression must be a linear algebra expression that does not involve control structures such as for, while etc.)\n",
    "- the result of evaluating the expression, assuming:\n",
    "$$ TD = \\left( \\begin{matrix} 2 & 3 & 0 & 3 & 7 \\\\ 0 & 5 & 5 & 0 & 3 \\\\ 5 & 0 & 7 & 3 & 3 \\\\ 3 & 1 & 0 & 9 & 9 \\\\ 0 & 0 & 7 & 1 & 3 \\\\ 6 & 9 & 4 & 6 & 0 \\end{matrix} \\right) \\hspace{1cm} A = \\left( \\begin{matrix} 5\\\\\n",
    "2\\\\\n",
    "3\\\\\n",
    "6\\\\\n",
    "4\\\\\n",
    "3 \\end{matrix} \\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7095293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 0 3 7]\n",
      " [0 5 5 0 3]\n",
      " [5 0 7 3 3]\n",
      " [3 1 0 9 9]\n",
      " [0 0 7 1 3]\n",
      " [6 9 4 6 0]]\n",
      "[5 2 3 6 4 3]\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "TD = np.array([[2,3,0,3,7],\n",
    "               [0,5,5,0,3],\n",
    "               [5,0,7,3,3],\n",
    "               [3,1,0,9,9],\n",
    "               [0,0,7,1,3],\n",
    "               [6,9,4,6,0]])\n",
    "L = np.array([5,2,3,6,4,3]).T\n",
    "print(TD)\n",
    "print(L)\n",
    "print(L.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b9589",
   "metadata": {},
   "source": [
    "> (a) Matrix P(T,D) (Each position of the matrix $P(T,D)_{i,j}$ corresponds to the joint probability of term $t_i$ and document $d_j$, $P(t_i,d_j)$)\n",
    "\n",
    "We define the joint probability as the probality of two events ocurring at the same time. That means we want $P(T \\cap D)$ that is:\n",
    "$$ P(T \\cap D) = P(T|D)P(D)$$ \n",
    "\n",
    "Also, we know $P(D)$ is randomly chosen with uniform probability, and $P(T|D)$ will be the probabilities values in that subset of the document choosen\n",
    "\n",
    "$$P(T_i|D_i) = \\frac{TD_{i,j}}{\\sum(TD_j)}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2df038b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.025     , 0.03333333, 0.        , 0.02727273, 0.056     ],\n",
       "       [0.        , 0.05555556, 0.04347826, 0.        , 0.024     ],\n",
       "       [0.0625    , 0.        , 0.06086957, 0.02727273, 0.024     ],\n",
       "       [0.0375    , 0.01111111, 0.        , 0.08181818, 0.072     ],\n",
       "       [0.        , 0.        , 0.06086957, 0.00909091, 0.024     ],\n",
       "       [0.075     , 0.1       , 0.03478261, 0.05454545, 0.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_documents = TD.shape[1]\n",
    "total_words_per_document = np.sum(TD, axis = 0)\n",
    "PTD = ((TD/total_words_per_document))*(1/n_documents)\n",
    "PTD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7bacf",
   "metadata": {},
   "source": [
    "> (b) Matrix $P(T|D)$\n",
    "\n",
    "It was explained in the previous block and taking into account both events are independent $P(T|D)$ is $P(T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a62db0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.125     , 0.16666667, 0.        , 0.13636364, 0.28      ],\n",
       "       [0.        , 0.27777778, 0.2173913 , 0.        , 0.12      ],\n",
       "       [0.3125    , 0.        , 0.30434783, 0.13636364, 0.12      ],\n",
       "       [0.1875    , 0.05555556, 0.        , 0.40909091, 0.36      ],\n",
       "       [0.        , 0.        , 0.30434783, 0.04545455, 0.12      ],\n",
       "       [0.375     , 0.5       , 0.17391304, 0.27272727, 0.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PTonD = (TD/total_words_per_document)\n",
    "PTonD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75342297",
   "metadata": {},
   "source": [
    "> (c) Matrix $P(D|T)$\n",
    "\n",
    "We can obtain this probability matrix using Baye´s theorem, as follows:\n",
    "$$ P(D|T) = \\frac{P(T|D)P(D)}{P(T)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d08160a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17654612, 0.23539482, 0.        , 0.19259576, 0.3954633 ],\n",
       "       [0.        , 0.45154704, 0.35338464, 0.        , 0.19506832],\n",
       "       [0.35787437, 0.        , 0.34853851, 0.15616336, 0.13742376],\n",
       "       [0.18524987, 0.05488885, 0.        , 0.40418153, 0.35567975],\n",
       "       [0.        , 0.        , 0.64782097, 0.09675248, 0.25542655],\n",
       "       [0.28373832, 0.37831776, 0.13158879, 0.20635514, 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability of D given a term\n",
    "Pd = 1/n_documents\n",
    "Pt = PTD #Joint probabilties\n",
    "PT = np.sum(Pt, axis = 1, keepdims = True) #Marginal probabilities of T\n",
    "pDonT = (PTonD*Pd)/PT\n",
    "pDonT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d4e6e",
   "metadata": {},
   "source": [
    "> (d) Vector $P(D)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5384c0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2],\n",
       "       [0.2],\n",
       "       [0.2],\n",
       "       [0.2],\n",
       "       [0.2]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PD = np.ones((n_documents,1))*(1/n_documents)\n",
    "PD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240eca9d",
   "metadata": {},
   "source": [
    "> (e) vector $P(T)$\n",
    "Is the marginal probability of T, so we can obtain it, as follows:\n",
    "$$\n",
    "P(X = x_i) = \\sum_j{P(X=x_i,Y=y_j)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edf1a3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14423077],\n",
       "       [0.125     ],\n",
       "       [0.17307692],\n",
       "       [0.21153846],\n",
       "       [0.10576923],\n",
       "       [0.24038462]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT = (TD/np.sum(TD)).sum(axis = 1, keepdims = True)\n",
    "PT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e8ebd",
   "metadata": {},
   "source": [
    "> (f) $E[l]$ (the expected value of the random variable l corresponding to the length of a randomly chosen term)\n",
    "The expectation of f(x), is the average value of a some function f(x) under the distribution P(X)\n",
    "$$\n",
    "E[f(x)] = \\sum_{x\\in X}{f(x)P(X=x)}\n",
    "$$\n",
    "\n",
    "L follows a uniform distribution, and the expected value of the distribution is:\n",
    "\n",
    "$$\\mu = E(l)=\\frac{1}{n}\\sum^n_{i=1}l_i=\\frac{\\sum(L)}{length(L)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3ad7810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8333333333333335"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EL = np.mean(L)\n",
    "EL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3df45c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8333333333333335"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EL = sum(L)/(len(L))\n",
    "EL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acda75",
   "metadata": {},
   "source": [
    "> (g) Var$(l)$ (the variance of $l$)\n",
    "Variance of f(X), under P(X), is a measure of the variation of f(x) around the mean E[f(X)]\n",
    "$$Var[f(X)] = E[(f(X)-E[f(X)])^2]$$\n",
    "And the variance of the uniform distribution is:\n",
    "$$Var(l)=\\frac{1}{n}\\sum^n_{i=1}(l_i-E(l))^2=\\frac{\\sum(L-E(l))^2}{length(L)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d3955da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8055555555555556"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varL = np.var(L)\n",
    "varL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ed08c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8055555555555556"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varL = (1/len(L))*np.sum((L-EL)**2)\n",
    "varL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25aba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
